x-env-file: &default-env
  env_file:
    # Development and production configs
    # Later files override earlier ones, so .env.prod overrides .env
    # Production: docker-compose --env-file .env.prod up
    # Development: docker-compose up (uses .env)
    - .env         # Development defaults
    - .env.memory  # Memory optimization settings
    - .env.prod    # Production overrides (loaded last, takes priority)

services:
  redis:
    image: redis:7-alpine
    container_name: redis
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    ports:
      - "${REDIS_HOST_PORT:-6379}:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - recommend-net

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.16.0
    container_name: mlflow
    <<: *default-env
    environment:
      MLFLOW_BACKEND_STORE_URI: sqlite:///mlflow/mlflow.db
      MLFLOW_DEFAULT_ARTIFACT_ROOT: /mlflow/artifacts
    volumes:
      - mlflow-data:/mlflow
    command: mlflow server --host 0.0.0.0 --port 5000 --serve-artifacts --artifacts-destination /mlflow/artifacts
    ports:
      - "${MLFLOW_HOST_PORT:-5000}:5000"
    networks:
      - recommend-net

  recommendation-api:
    build:
      context: .
      dockerfile: Dockerfile
    image: recommend-recommendation-api
    container_name: recommendation-api
    <<: *default-env
    environment:
      REDIS_URL: redis://redis:6379/0
      FEATURE_REDIS_URL: redis://redis:6379/1
      MLFLOW_TRACKING_URI: http://mlflow:5000
      DATA_DIR: /app/data
      MODELS_DIR: /app/models
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      HF_ENDPOINT: ${HF_ENDPOINT:-https://hf-mirror.com}
      # Sentry 监控配置
      SENTRY_DSN: ${SENTRY_DSN}
      SENTRY_ENVIRONMENT: ${SENTRY_ENVIRONMENT:-production}
      SENTRY_TRACES_SAMPLE_RATE: ${SENTRY_TRACES_SAMPLE_RATE:-0.1}
      SENTRY_PROFILES_SAMPLE_RATE: ${SENTRY_PROFILES_SAMPLE_RATE:-0.1}
      SENTENCE_TRANSFORMERS_HOME: /opt/recommend/cache/sentence-transformers
      HF_HOME: /opt/recommend/cache/huggingface
      TRANSFORMERS_CACHE: /opt/recommend/cache/huggingface/hub
      CLIP_MODEL_PATH: /opt/recommend/cache/sentence-transformers/clip-ViT-B-32
      HF_HUB_OFFLINE: "1"
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
      - ./cache:/opt/recommend/cache
    ports:
      - "${RECOMMEND_API_HOST_PORT:-8000}:8000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      redis:
        condition: service_healthy
      mlflow:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s
    networks:
      - recommend-net

  report-viewer:
    image: recommend-recommendation-api
    container_name: report-viewer
    <<: *default-env
    environment:
      DAILY_REPORT_DIR: /app/data/evaluation/daily_reports
    command:
      [
        "/opt/venv/bin/uvicorn",
        "report_viewer.app:app",
        "--host",
        "0.0.0.0",
        "--port",
        "8800",
      ]
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    ports:
      - "${REPORT_VIEWER_HOST_PORT:-8800}:8800"
    depends_on:
      recommendation-api:
        condition: service_started
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - recommend-net

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: recommend-airflow:latest
    container_name: airflow-init
    restart: "no"
    entrypoint: /bin/bash
    command: >
      -c "airflow db init &&
          airflow users create --role Admin --username ${AIRFLOW_USERNAME:-admin} --password ${AIRFLOW_PASSWORD:-admin} --firstname Admin --lastname User --email admin@example.com"
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      PYTHONPATH: /opt/recommend
      DATA_DIR: /opt/recommend/data
      MLFLOW_TRACKING_URI: http://mlflow:5000
      SENTENCE_TRANSFORMERS_HOME: /opt/recommend/cache/sentence-transformers
      HF_HOME: /opt/recommend/cache/huggingface
      TRANSFORMERS_CACHE: /opt/recommend/cache/huggingface/hub
      CLIP_MODEL_PATH: /opt/recommend/cache/sentence-transformers/clip-ViT-B-32
      HF_HUB_OFFLINE: "1"
    depends_on:
      postgres-airflow:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - .:/opt/recommend
      - mlflow-data:/mlflow
      - /dianshu/backup/data/dianshu_data/jsons:/dianshu/backup/data/dianshu_data/jsons:ro
      - /opt/recommend/cache/sentence-transformers:/opt/recommend/cache/sentence-transformers
      - /opt/recommend/cache/huggingface:/opt/recommend/cache/huggingface
      - /root/recommendation-system/models/sbert:/root/recommendation-system/models/sbert
    networks:
      - recommend-net

  postgres-airflow:
    image: postgres:15
    container_name: postgres-airflow
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-airflow-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - recommend-net

  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: recommend-airflow:latest
    container_name: airflow-webserver
    restart: unless-stopped
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    <<: *default-env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY:-}
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      REDIS_URL: redis://redis:6379/0
      FEATURE_REDIS_URL: redis://redis:6379/1
      # Sentry 监控配置
      SENTRY_DSN: ${SENTRY_DSN}
      SENTRY_ENVIRONMENT: ${SENTRY_ENVIRONMENT:-production}
      PYTHONPATH: /opt/recommend
      DATA_DIR: /opt/recommend/data
      MLFLOW_TRACKING_URI: http://mlflow:5000
      HF_ENDPOINT: ${HF_ENDPOINT:-https://hf-mirror.com}
      SENTENCE_TRANSFORMERS_HOME: /opt/recommend/cache/sentence-transformers
      HF_HOME: /opt/recommend/cache/huggingface
      TRANSFORMERS_CACHE: /opt/recommend/cache/huggingface/hub
      CLIP_MODEL_PATH: /opt/recommend/cache/sentence-transformers/clip-ViT-B-32
      HF_HUB_OFFLINE: "1"
    volumes:
      - .:/opt/recommend
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - mlflow-data:/mlflow
      - /dianshu/backup/data/dianshu_data/jsons:/dianshu/backup/data/dianshu_data/jsons:ro
      - ./cache:/opt/recommend/cache
      - /root/recommendation-system/models/sbert:/root/recommendation-system/models/sbert
    ports:
      - "${AIRFLOW_WEB_HOST_PORT:-8080}:8080"
    command: webserver
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - recommend-net

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: recommend-airflow:latest
    container_name: airflow-scheduler
    restart: unless-stopped
    depends_on:
      airflow-webserver:
        condition: service_started
    <<: *default-env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      REDIS_URL: redis://redis:6379/0
      FEATURE_REDIS_URL: redis://redis:6379/1
      # Sentry 监控配置
      SENTRY_DSN: ${SENTRY_DSN}
      SENTRY_ENVIRONMENT: ${SENTRY_ENVIRONMENT:-production}
      PYTHONPATH: /opt/recommend
      DATA_DIR: /opt/recommend/data
      MLFLOW_TRACKING_URI: http://mlflow:5000
      HF_ENDPOINT: ${HF_ENDPOINT:-https://hf-mirror.com}
      SENTENCE_TRANSFORMERS_HOME: /opt/recommend/cache/sentence-transformers
      HF_HOME: /opt/recommend/cache/huggingface
      TRANSFORMERS_CACHE: /opt/recommend/cache/huggingface/hub
      CLIP_MODEL_PATH: /opt/recommend/cache/sentence-transformers/clip-ViT-B-32
      # HF_HUB_OFFLINE: "1"  # 注释掉以允许从镜像下载SBERT模型
      # 数据源配置
      DATA_SOURCE: ${DATA_SOURCE:-json}
      BUSINESS_DATA_SOURCE: ${BUSINESS_DATA_SOURCE:-json}
      MATOMO_DATA_SOURCE: ${MATOMO_DATA_SOURCE:-database}
      DATA_JSON_DIR: ${DATA_JSON_DIR}
      DATASET_IMAGE_ROOT: ${DATASET_IMAGE_ROOT}
      # SBERT 和文本嵌入配置
      SBERT_MODEL: ${SBERT_MODEL:-paraphrase-multilingual-MiniLM-L12-v2}
      TEXT_PCA_COMPONENTS: ${TEXT_PCA_COMPONENTS:-10}
      TEXT_EMBED_BATCH_SIZE: ${TEXT_EMBED_BATCH_SIZE:-64}
      TEXT_EMBED_WORKERS: ${TEXT_EMBED_WORKERS:-1}
      TEXT_EMBED_CHUNK_SIZE: ${TEXT_EMBED_CHUNK_SIZE:-1000}
      # 训练加速配置
      RANKER_ESTIMATORS: ${RANKER_ESTIMATORS:-150}
      RANKER_LEARNING_RATE: ${RANKER_LEARNING_RATE:-0.1}
      RANKER_NUM_LEAVES: ${RANKER_NUM_LEAVES:-31}
      SIMILARITY_BATCH_SIZE: ${SIMILARITY_BATCH_SIZE:-2000}
    volumes:
      - mlflow-data:/mlflow
      - .:/opt/recommend
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - /dianshu/backup/data/dianshu_data/jsons:/dianshu/backup/data/dianshu_data/jsons:ro
      - ./cache:/opt/recommend/cache
      - /root/recommendation-system/models/sbert:/root/recommendation-system/models/sbert
    command: scheduler
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - recommend-net

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
    ports:
      - "${PROMETHEUS_HOST_PORT:-9090}:9090"
    networks:
      - recommend-net

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
    ports:
      - "${ALERTMANAGER_HOST_PORT:-9093}:9093"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - recommend-net

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "${GRAFANA_HOST_PORT:-3000}:3000"
    depends_on:
      - prometheus
      - alertmanager
    networks:
      - recommend-net

  notification-gateway:
    build:
      context: ./notification_gateway
      dockerfile: Dockerfile
    container_name: notification-gateway
    <<: *default-env
    environment:
      WEIXIN_CORP_ID: ${WEIXIN_CORP_ID}
      WEIXIN_CORP_SECRET: ${WEIXIN_CORP_SECRET}
      WEIXIN_AGENT_ID: ${WEIXIN_AGENT_ID:-1000019}
      WEIXIN_DEFAULT_USER: ${WEIXIN_DEFAULT_USER:-ZhangJinBo}
      SENTENCE_TRANSFORMERS_HOME: /opt/recommend/cache/sentence-transformers
      HF_HOME: /opt/recommend/cache/huggingface
      TRANSFORMERS_CACHE: /opt/recommend/cache/huggingface/hub
      CLIP_MODEL_PATH: /opt/recommend/cache/sentence-transformers/clip-ViT-B-32
      HF_HUB_OFFLINE: "1"
    # 使用宿主机网络，绕过企业微信 IP 白名单限制
    network_mode: host
    volumes:
      - /opt/recommend/cache/sentence-transformers:/opt/recommend/cache/sentence-transformers
      - /opt/recommend/cache/huggingface:/opt/recommend/cache/huggingface

networks:
  recommend-net:
    driver: bridge

volumes:
  postgres-airflow-data:
  redis-data:
  mlflow-data:
  prometheus-data:
  grafana-data:
