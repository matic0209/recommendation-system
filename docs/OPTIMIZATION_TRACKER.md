# 推荐系统优化追踪清单

## 背景

面向数据交易场景的推荐系统已经覆盖离线流水线、在线服务、实验与监控等核心能力。为保障在生产环境的可扩展性与稳定性，需要将当前识别的优化项形成文档化清单，便于排期、协作与验收。

## 优化项目概览

| 编号 | 主题 | 影响范围 | 优先级 | 当前状态 |
| --- | --- | --- | --- | --- |
| P0-01 | 离线抽取分批 & CDC 容错 | 业务库、Matomo 行为库 | 高 | 进行中 |
| P0-02 | 数据契约与质量告警 | 离线流水线、监控 | 高 | 进行中 |
| P0-03 | 特征存储解耦与增量同步 | 特征工程、在线服务 | 中 | 待排期 |
| P0-04 | 在线服务弹性与限流 | 推荐 API、部署架构 | 中 | 待排期 |
| P0-05 | 模型迭代与实验治理 | 模型训练、实验平台 | 中 | 待排期 |
| P0-06 | 可观测性与安全治理 | 监控、合规 | 中 | 待排期 |

> 优先级定义：高 = 阻塞上线/影响核心指标；中 = 提升稳定性或效率；低 = 增强/体验优化。

## 详细优化项

### P0-01 离线抽取分批 & CDC 容错
- **现状**：`pipeline/extract_load.py:210` 每次将全表读入内存，数据体量一旦过亿行会占用大量资源。未对超时、网络抖动设置重试。
- **优化方向**：
  - 将 `pd.read_sql_query` 改造为分片拉取（`chunksize` + 主键区间），对 Matomo 等大表按照天/小时分段。
  - 在 `create_engine` 初始化（`pipeline/extract_load.py:183`）增加连接超时、退避重试和熔断配置，必要时接入连接池监控。
  - 评估引入 Debezium/Kafka Connect，改用 binlog CDC 减轻业务库压力。
- **交付物**：抽取脚本与配置改造、性能对比报告、回归测试。
- **进度**：
  - 2025-10-10：抽取脚本支持分块流式写入并增加失败重试（`pipeline/extract_load.py`）。

### P0-02 数据契约与质量告警
- **现状**：依赖 `_select_incremental_column` 自动推断，字段变更或类型漂移时无法及时发现；`pipeline/data_quality_v2.py` 产物未直接接告警。
- **优化方向**：
  - 为业务库、Matomo 样表建立 schema 契约（Great Expectations/DBT tests），并纳入 CI。
  - 将质量得分、核心指标对账写入 Prometheus/AlertManager，实现阈值告警。
  - 对关键指标（订单量、曝光日志）提供日级对账脚本，确保行为与业务侧一致。
- **交付物**：契约配置、告警规则、对账报告模版。
- **进度**：
  - 2025-10-10：落地 `config/schema_contracts.yaml` 与 `pipeline/schema_contracts.py`，数据质量脚本自动生成 schema 合规指标，并写入 Prometheus 快照（`data_quality_metrics.prom`）。
  - 2025-10-10：新增数据质量与 Schema 违规告警规则（`monitoring/alerts/recommendation.yml`），并发布业务/行为日级对账脚本（`scripts/reconcile_business_metrics.py`）。

### P0-03 特征存储解耦与增量同步
- **现状**：在线服务主要依赖本地 SQLite（`app/main.py:333`）与单实例 Redis（`pipeline/feature_store_redis.py:44`），全量 `delete+hset`（`pipeline/feature_store_redis.py:66`、`pipeline/feature_store_redis.py:105`）造成写放大。
- **优化方向**：
  - 迁移至托管特征库（Feast、Redis Cluster、KeyDB 等），并为数据加上版本号/TTL。
  - 引入增量同步策略（基于更新时间/水位），替换全量清空写入。
  - 对多实例部署提供读写隔离策略，避免 SQLite 锁争用。
- **交付物**：新特征存储方案设计、迁移脚本、性能压测结果。

### P0-04 在线服务弹性与限流
- **现状**：FastAPI 使用固定 4 个线程处理阻塞 I/O（`app/main.py:54`），缺少多进程与限流策略。
- **优化方向**：
  - 根据 CPU 核数和下游延迟动态调整线程池，或改为 gunicorn + 多 worker 模式。
  - 引入异步 Redis/MySQL 客户端，将召回/排序 I/O 异步化。
  - 扩展 `TimeoutManager` 实现分级超时+熔断，对 `/models/reload` 等管理接口增加限流与幂等保护。
  - 补充压测脚本与 Prometheus 仪表盘，验证 QPS/P95 改善。
- **交付物**：部署配置、压测报告、监控图表更新。

### P0-05 模型迭代与实验治理
- **现状**：Airflow DAG（`airflow/dags/recommendation_pipeline.py:31`）按日全量运行，实验通过 YAML 静态配置，缺少业务事件驱动和自动化回流。
- **优化方向**：
  - 增加事件触发（新增数据集、订单量波动）缩短模型迭代周期。
  - 将实验权重、曝光、转化数据写入统一实验平台，自动生成 CTR/CVR/GMV 回流。
  - 对模型上线引入灰度/影子验证的自动指标阈值，避免回滚滞后。
- **交付物**：事件触发规则、实验数据同步流程、上线验证手册。

### P0-06 可观测性与安全治理
- **现状**：已有 Prometheus 指标，但缺少分布式追踪、安全审计与容量规划。
- **优化方向**：
  - 集成 OpenTelemetry，对召回、排序、特征查询链路打 trace，结合日志定位瓶颈。
- **交付物**：Tracing 配置、权限策略文档、容量与灾备方案。

## 后续维护方式

- 每个优化项指定负责人与里程碑，在 MR/PR 中回链此文档更新状态。
- 当优化完成时，将状态更新为「完成」，并链接至验证报告/仪表盘。
- 若新增优化点，按编号顺序追加到概览表，保持版本记录。
