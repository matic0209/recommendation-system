# æ¨èç³»ç»Ÿéƒ¨ç½²æŒ‡å—ï¼ˆJSON æ•°æ®æºæ¨¡å¼ï¼‰

æœ¬æ–‡æ¡£é€‚ç”¨äº**ä½¿ç”¨ JSON æ–‡ä»¶ä½œä¸ºæ•°æ®æº**çš„å¿«é€Ÿéƒ¨ç½²ã€‚

## ğŸ“‹ å‰ææ¡ä»¶

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**ï¼šLinux (Ubuntu 20.04+ / CentOS 8+)
- **ç¡¬ä»¶**ï¼š4æ ¸+ CPUï¼Œ8GB+ å†…å­˜ï¼Œ20GB+ ç£ç›˜
- **è½¯ä»¶**ï¼š
  - Docker 20.10+
  - Docker Compose v2
  - Python 3.8+
  - Git 2.20+

### å®‰è£… Dockerï¼ˆå¦‚æœæœªå®‰è£…ï¼‰

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install -y docker.io docker-compose-v2 python3 python3-pip git
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -aG docker $USER
newgrp docker
```

**CentOS/RHEL:**
```bash
sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo yum install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin python3 git
sudo systemctl start docker
sudo systemctl enable docker
sudo usermod -aG docker $USER
```

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æ­¥éª¤

### 1. å…‹éš†ä»£ç 

```bash
# å…‹éš†åˆ°æ¨èç›®å½•
git clone <repository-url> /opt/recommend
cd /opt/recommend
```

### 2. å‡†å¤‡ JSON æ•°æ®æ–‡ä»¶

å°† JSON æ•°æ®æ–‡ä»¶æ”¾åˆ° `data/dianshu_data/` ç›®å½•ï¼š

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/dianshu_data

# å°† JSON æ–‡ä»¶å¤åˆ¶åˆ°æ­¤ç›®å½•
# éœ€è¦ä»¥ä¸‹æ–‡ä»¶ï¼š
# - user.json
# - dataset.json
# - task.json
# - api_order.json
# - dataset_image.json
```

**JSON æ–‡ä»¶æ ¼å¼ç¤ºä¾‹ï¼š**
```json
[
  {
    "id": 1,
    "user_name": "å¼ ä¸‰",
    "update_time": "2025-10-16T14:00:00"
  }
]
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶é…ç½®æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim .env
```

**å¿…è¦çš„é…ç½®é¡¹ï¼š**

```ini
# ============ æ•°æ®æºé…ç½®ï¼ˆJSON æ¨¡å¼ï¼‰============
DATA_SOURCE=json
DATA_JSON_DIR=/opt/recommend/data/dianshu_data

# ============ Redis é…ç½® ============
REDIS_URL=redis://redis:6379/0
FEATURE_REDIS_URL=redis://redis:6379/1

# ============ MLflow é…ç½® ============
MLFLOW_TRACKING_URI=http://mlflow:5000
MLFLOW_EXPERIMENT_NAME=dataset_recommendation

# ============ ä¼ä¸šå¾®ä¿¡é€šçŸ¥é…ç½®ï¼ˆå¯é€‰ï¼‰============
WEIXIN_CORP_ID=your_corp_id
WEIXIN_CORP_SECRET=your_corp_secret
WEIXIN_AGENT_ID=1000019
WEIXIN_DEFAULT_USER=YourName
```

**é‡è¦æç¤ºï¼š**
- `DATA_JSON_DIR` å¿…é¡»æ˜¯**ç»å¯¹è·¯å¾„**
- å¦‚æœä½¿ç”¨ Dockerï¼Œå»ºè®®ä½¿ç”¨å®¹å™¨å†…çš„è·¯å¾„ï¼š`/app/data/dianshu_data`
- ä¼ä¸šå¾®ä¿¡é…ç½®æ˜¯å¯é€‰çš„ï¼Œç”¨äºå‘Šè­¦é€šçŸ¥

### 4. å®‰è£… Python ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install --upgrade pip
pip install -r requirements.txt

# å¯é€‰ï¼šå‘é‡æ£€ç´¢æ”¯æŒ
pip install faiss-cpu skl2onnx
```

### 5. è¿è¡Œæ•°æ®å¤„ç† Pipeline

```bash
# è®¾ç½® Python è·¯å¾„
export PYTHONPATH=/opt/recommend:$PYTHONPATH

# æ–¹å¼ Aï¼šä¸€é”®è¿è¡Œå®Œæ•´ Pipelineï¼ˆæ¨èï¼‰
bash scripts/run_pipeline.sh

# æ–¹å¼ Bï¼šåˆ†æ­¥æ‰§è¡Œï¼ˆè°ƒè¯•ç”¨ï¼‰
python3 -m pipeline.extract_load      # æ•°æ®æŠ½å–
python3 -m pipeline.clean_data        # æ•°æ®æ¸…æ´—
python3 -m pipeline.build_features_v2 # ç‰¹å¾å·¥ç¨‹
python3 -m pipeline.train_models      # æ¨¡å‹è®­ç»ƒ
python3 -m pipeline.recall_engine_v2  # å¬å›å¼•æ“
python3 -m pipeline.evaluate_quality_v2  # è´¨é‡è¯„ä¼°
```

**é¢„è®¡æ‰§è¡Œæ—¶é—´ï¼š** 30-60 åˆ†é’Ÿï¼ˆå–å†³äºæ•°æ®é‡ï¼‰

### 6. å¯åŠ¨ Docker æœåŠ¡

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker compose ps

# æŸ¥çœ‹æ—¥å¿—
docker compose logs -f
```

**å¯åŠ¨çš„æœåŠ¡ï¼š**
| æœåŠ¡å | ç«¯å£ | è¯´æ˜ |
|--------|------|------|
| redis | 6379 | ç¼“å­˜å’Œç‰¹å¾å­˜å‚¨ |
| mlflow | 5000 | æ¨¡å‹ç®¡ç† |
| recommendation-api | 8000 | æ¨è API |
| prometheus | 9090 | ç›‘æ§æŒ‡æ ‡é‡‡é›† |
| grafana | 3000 | ç›‘æ§çœ‹æ¿ |
| alertmanager | 9093 | å‘Šè­¦ç®¡ç† |
| notification-gateway | 9000 | ä¼ä¸šå¾®ä¿¡é€šçŸ¥ |
| airflow-webserver | 8080 | æ•°æ®æµæ°´çº¿ UI |
| airflow-scheduler | - | è°ƒåº¦å™¨ï¼ˆåå°ï¼‰ |
| postgres-airflow | 5432 | Airflow å…ƒæ•°æ®åº“ |

### 7. éªŒè¯éƒ¨ç½²

```bash
# 1. å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# é¢„æœŸè¾“å‡ºï¼š
# {
#   "status": "healthy",
#   "cache": "enabled",
#   "models_loaded": true
# }

# 2. æµ‹è¯•æ¨èæ¥å£
curl "http://localhost:8000/similar/123?top_n=10"

# 3. æµ‹è¯•ä¼ä¸šå¾®ä¿¡é€šçŸ¥ï¼ˆå¯é€‰ï¼‰
curl -X POST http://localhost:9000/test

# 4. æŸ¥çœ‹ç›‘æ§é¢æ¿
# Prometheus: http://localhost:9090
# Grafana: http://localhost:3000 (admin/admin)
# MLflow: http://localhost:5000
# Airflow: http://localhost:8080 (admin/admin)
```

---

## ğŸ“ ç›®å½•ç»“æ„

éƒ¨ç½²å®Œæˆåçš„ç›®å½•ç»“æ„ï¼š

```
/opt/recommend/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dianshu_data/          # JSON æ•°æ®æºï¼ˆè¾“å…¥ï¼‰
â”‚   â”‚   â”œâ”€â”€ user.json
â”‚   â”‚   â”œâ”€â”€ dataset.json
â”‚   â”‚   â”œâ”€â”€ task.json
â”‚   â”‚   â”œâ”€â”€ api_order.json
â”‚   â”‚   â””â”€â”€ dataset_image.json
â”‚   â”œâ”€â”€ business/              # ä¸šåŠ¡æ•°æ®ï¼ˆParquetï¼‰
â”‚   â”œâ”€â”€ cleaned/               # æ¸…æ´—åæ•°æ®
â”‚   â”œâ”€â”€ processed/             # ç‰¹å¾æ•°æ®
â”‚   â””â”€â”€ evaluation/            # è¯„ä¼°æŠ¥å‘Š
â”œâ”€â”€ models/                    # æ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ item_sim_behavior.pkl
â”‚   â”œâ”€â”€ item_sim_content.pkl
â”‚   â”œâ”€â”€ rank_model.pkl
â”‚   â”œâ”€â”€ rank_model.onnx
â”‚   â””â”€â”€ model_registry.json
â”œâ”€â”€ logs/                      # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ notification_gateway/      # ä¼ä¸šå¾®ä¿¡é€šçŸ¥æœåŠ¡
â”œâ”€â”€ monitoring/                # ç›‘æ§é…ç½®
â”œâ”€â”€ airflow/                   # Airflow DAGs
â”œâ”€â”€ .env                       # ç¯å¢ƒå˜é‡é…ç½®
â””â”€â”€ docker-compose.yml         # Docker æœåŠ¡ç¼–æ’
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### 1. JSON æ•°æ®æ–‡ä»¶æ‰¾ä¸åˆ°

**é”™è¯¯ï¼š** `FileNotFoundError: data/dianshu_data/user.json`

**è§£å†³ï¼š**
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -lh data/dianshu_data/

# ç¡®ä¿ .env ä¸­çš„è·¯å¾„æ­£ç¡®
cat .env | grep DATA_JSON_DIR

# ç¡®ä¿æ–‡ä»¶å‘½åæ­£ç¡®ï¼ˆå¿…é¡»æ˜¯ user.jsonï¼Œä¸æ˜¯ users.jsonï¼‰
```

### 2. æ¨¡å‹åŠ è½½å¤±è´¥

**é”™è¯¯ï¼š** `models_loaded: false`

**è§£å†³ï¼š**
```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
ls -lh models/

# é‡æ–°è®­ç»ƒæ¨¡å‹
bash scripts/run_pipeline.sh

# æ£€æŸ¥ models/model_registry.json
cat models/model_registry.json
```

### 3. Redis è¿æ¥å¤±è´¥

**é”™è¯¯ï¼š** `redis.exceptions.ConnectionError`

**è§£å†³ï¼š**
```bash
# æ£€æŸ¥ Redis å®¹å™¨
docker compose ps redis

# æŸ¥çœ‹ Redis æ—¥å¿—
docker compose logs redis

# é‡å¯ Redis
docker compose restart redis

# æµ‹è¯•è¿æ¥
redis-cli ping
```

### 4. Docker ç«¯å£å†²çª

**é”™è¯¯ï¼š** `Bind for 0.0.0.0:8000 failed: port is already allocated`

**è§£å†³ï¼š**
```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
sudo netstat -tlnp | grep 8000

# æ–¹å¼ 1ï¼šåœæ­¢å ç”¨ç«¯å£çš„æœåŠ¡
sudo kill <PID>

# æ–¹å¼ 2ï¼šä¿®æ”¹ docker-compose.yml æ”¹ç”¨å…¶ä»–ç«¯å£
# ä¾‹å¦‚å°† 8000:8000 æ”¹ä¸º 8001:8000
```

### 5. ä¼ä¸šå¾®ä¿¡å‘é€å¤±è´¥ï¼ˆé”™è¯¯ç  60020ï¼‰

**é”™è¯¯ï¼š** `not allow to access from your ip`

**è§£å†³ï¼š**
1. ç™»å½•ä¼ä¸šå¾®ä¿¡ç®¡ç†åå°ï¼šhttps://work.weixin.qq.com/
2. è¿›å…¥"åº”ç”¨ç®¡ç†" -> æ‰¾åˆ°å¯¹åº”åº”ç”¨
3. é…ç½®"ä¼ä¸šå¯ä¿¡ IP"ï¼Œæ·»åŠ æœåŠ¡å™¨å…¬ç½‘ IP
4. ä¿å­˜åé‡è¯•

---

## ğŸ”„ æ—¥å¸¸è¿ç»´

### æ›´æ–°æ•°æ®

```bash
# 1. å°†æ–°çš„ JSON æ–‡ä»¶æ”¾å…¥ data/dianshu_data/
# æ”¯æŒå¢é‡æ–‡ä»¶ï¼šdataset_20251016_140000.json

# 2. é‡æ–°è¿è¡Œ Pipeline
bash scripts/run_pipeline.sh

# 3. é‡å¯ APIï¼ˆè‡ªåŠ¨åŠ è½½æ–°æ¨¡å‹ï¼‰
docker compose restart recommendation-api
```

### æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹ API æ—¥å¿—
docker compose logs -f recommendation-api

# æŸ¥çœ‹é€šçŸ¥ç½‘å…³æ—¥å¿—
docker compose logs -f notification-gateway

# æŸ¥çœ‹ Airflow æ—¥å¿—
docker compose logs -f airflow-scheduler
```

### å¤‡ä»½

```bash
# å¤‡ä»½æ¨¡å‹
tar -czf models_backup_$(date +%Y%m%d).tar.gz models/

# å¤‡ä»½æ•°æ®
tar -czf data_backup_$(date +%Y%m%d).tar.gz data/processed/

# å¤‡ä»½é…ç½®
cp .env .env.backup
```

### åœæ­¢æœåŠ¡

```bash
# åœæ­¢æ‰€æœ‰æœåŠ¡
docker compose down

# åœæ­¢å¹¶åˆ é™¤æ‰€æœ‰æ•°æ®
docker compose down -v
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

| æŒ‡æ ‡ | å‚è€ƒå€¼ |
|------|--------|
| API QPS | > 100 (å• worker) |
| P95 å»¶è¿Ÿ | < 100ms (æœ‰ç¼“å­˜) |
| P99 å»¶è¿Ÿ | < 500ms |
| ç¼“å­˜å‘½ä¸­ç‡ | > 80% |
| å†…å­˜å ç”¨ | < 4GB (å« Redis) |
| Pipeline æ‰§è¡Œæ—¶é—´ | 30-60 åˆ†é’Ÿ |

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [å®Œæ•´éƒ¨ç½²æ¸…å•](DEPLOYMENT_CHECKLIST.md) - è¯¦ç»†çš„éƒ¨ç½²æ£€æŸ¥æ¸…å•
- [JSON æ•°æ®æºè¯´æ˜](JSON_DATA_SOURCE.md) - JSON æ–‡ä»¶æ ¼å¼è¯¦è§£
- [API æ¥å£æ–‡æ¡£](API_REFERENCE.md) - API ä½¿ç”¨è¯´æ˜
- [è¿ç»´æ‰‹å†Œ](OPERATIONS_SOP.md) - æ—¥å¸¸è¿ç»´æŒ‡å—
- [ä¼ä¸šå¾®ä¿¡é€šçŸ¥é…ç½®](../notification_gateway/README.md) - Alertmanager é€šçŸ¥è®¾ç½®

---

## âœ… éƒ¨ç½²æ£€æŸ¥æ¸…å•

éƒ¨ç½²å®Œæˆåï¼Œè¯·ç¡®è®¤ä»¥ä¸‹é¡¹ç›®ï¼š

- [ ] JSON æ•°æ®æ–‡ä»¶å·²å‡†å¤‡ï¼ˆuser.json, dataset.json ç­‰ï¼‰
- [ ] .env é…ç½®æ–‡ä»¶å·²æ­£ç¡®é…ç½®
- [ ] Python ä¾èµ–å·²å®‰è£…
- [ ] Pipeline æˆåŠŸæ‰§è¡Œï¼Œç”Ÿæˆæ¨¡å‹æ–‡ä»¶
- [ ] Docker æœåŠ¡å…¨éƒ¨å¯åŠ¨
- [ ] API å¥åº·æ£€æŸ¥è¿”å› healthy
- [ ] æ¨èæ¥å£æ­£å¸¸è¿”å›ç»“æœ
- [ ] Redis ç¼“å­˜æ­£å¸¸å·¥ä½œ
- [ ] Prometheus æŒ‡æ ‡å¯è®¿é—®
- [ ] ï¼ˆå¯é€‰ï¼‰ä¼ä¸šå¾®ä¿¡é€šçŸ¥é…ç½®å®Œæˆ

---

**éƒ¨ç½²æ—¶é—´ä¼°è®¡ï¼š** 1-2 å°æ—¶ï¼ˆé¦–æ¬¡éƒ¨ç½²ï¼‰

**ç»´æŠ¤è€…ï¼š** æ¨èç³»ç»Ÿå›¢é˜Ÿ
**æœ€åæ›´æ–°ï¼š** 2025-10-16
**ç‰ˆæœ¬ï¼š** v1.0
