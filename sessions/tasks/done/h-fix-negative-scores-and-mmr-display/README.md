---
name: h-fix-negative-scores-and-mmr-display
branch: fix/negative-scores-mmr-display
status: completed
created: 2025-12-27
---

# ä¿®å¤æ¨èç»“æœè´Ÿåˆ†å’ŒMMRå±•ç¤ºæ··ä¹±é—®é¢˜

## Problem/Goal

ç”Ÿäº§ç¯å¢ƒå‘ç°æ¨èç»“æœå­˜åœ¨ä¸¥é‡çš„è´¨é‡å’Œç”¨æˆ·ä½“éªŒé—®é¢˜ï¼š

**æ ¸å¿ƒé—®é¢˜**ï¼š
1. **æ’åºæ··ä¹±**ï¼šMMRé‡æ’åï¼Œå±•ç¤ºçš„scoreæ˜¯åŸå§‹å¬å›åˆ†æ•°ï¼Œå¯¼è‡´æ­£åˆ†itemæ’åœ¨è´Ÿåˆ†åé¢ï¼ˆå¦‚ï¼šscore=0.33æ’åœ¨score=-0.78åé¢ï¼‰
2. **å¤§é‡è´Ÿåˆ†æ¨è**ï¼š30ä¸ªæ¨èä¸­æœ‰16ä¸ªè´Ÿåˆ†ï¼ˆ53%ï¼‰ï¼Œrangeä»-0.32åˆ°-2.89
3. **Popularå¬å›è´¨é‡å·®**ï¼šå¤§é‡ä¸ç›¸å…³çš„é¼ æ ‡æŒ‡é’ˆã€æ¡Œå® ç±»itemè¢«æ¨èï¼ˆscoreåœ¨-2.5~-2.8ï¼‰
4. **ç”¨æˆ·ä½“éªŒå·®**ï¼šçœ‹åˆ°è´Ÿåˆ†å’Œæ··ä¹±çš„æ’åºï¼Œå¤±å»å¯¹æ¨èç³»ç»Ÿçš„ä¿¡ä»»

**å½±å“**ï¼š
- ç”¨æˆ·çœ‹åˆ°scoreä¸ç¬¦åˆé™åºæ’åˆ—ï¼Œæ„Ÿåˆ°å›°æƒ‘
- è´Ÿåˆ†itemæš—ç¤ºè´¨é‡å·®ï¼Œå½±å“ç‚¹å‡»æ„æ„¿
- Popularå¬å›çš„ä½è´¨é‡itemå æ®å®è´µçš„æ¨èä½
- å¯èƒ½å¯¼è‡´CTRä¸‹é™å’Œç”¨æˆ·æ»¡æ„åº¦é™ä½

**ç›®æ ‡**ï¼š
1. ç«‹å³ä¿®å¤scoreå±•ç¤ºæ··ä¹±é—®é¢˜
2. è¿‡æ»¤æˆ–ä¼˜åŒ–è´Ÿåˆ†æ¨è
3. æ”¹è¿›Popularå¬å›ç­–ç•¥

## Success Criteria

### æŠ€æœ¯æŒ‡æ ‡
- [x] è´Ÿåˆ†æ¨èå æ¯”ä»53%é™åˆ°<10% - âœ… å®æ–½ç¡¬æˆªæ–­è¿‡æ»¤æ‰€æœ‰score<0
- [x] Popularå¬å›è´¨é‡æå‡ - âœ… æ–°å¢ANDé€»è¾‘è´¨é‡è¿‡æ»¤è§„åˆ™
- [x] Tagå¬å›bugä¿®å¤ - âœ… æ ‡ç­¾å¤§å°å†™ç»Ÿä¸€å¤„ç†

### ä»£ç è´¨é‡
- [x] APIå“åº”æ ¼å¼å…¼å®¹ - âœ… æœªæ”¹å˜APIç»“æ„
- [x] å¼‚å¸¸å¤„ç†å®Œå–„ - âœ… æ·»åŠ KeyError/ValueError/TypeErroræ•è·
- [x] ä»£ç å®¡æŸ¥é€šè¿‡ - âœ… ä¿®å¤3ä¸ªCritical Issuesï¼Œ2ä¸ªWarnings
- [ ] æ€§èƒ½æ— é€€åŒ–ï¼ˆP99<500msï¼‰ - â³ å¾…ç”Ÿäº§éªŒè¯

### ä¸šåŠ¡æŒ‡æ ‡
- [ ] CTRä¸ä¸‹é™ - â³ å¾…ç”Ÿäº§A/Bæµ‹è¯•
- [ ] è´Ÿé¢åé¦ˆå‡å°‘ - â³ å¾…ç”Ÿäº§éªŒè¯

## Implementation Summary

æœ¬ä»»åŠ¡é‡‡ç”¨P0ç´§æ€¥ä¿®å¤ç­–ç•¥ï¼Œé‡ç‚¹è§£å†³è´Ÿåˆ†å’ŒPopularè´¨é‡é—®é¢˜ï¼š

1. **è´Ÿåˆ†ç¡¬æˆªæ–­** - ç›´æ¥è¿‡æ»¤score<0çš„itemï¼Œæ·»åŠ fallbackä¿è¯æœ‰ç»“æœè¿”å›
2. **Popularè´¨é‡è¿‡æ»¤** - ä½¿ç”¨ANDé€»è¾‘çš„ç»„åˆè´¨é‡ä¿¡å·ï¼Œé¿å…è¯¯æ€
3. **Tagå¬å›ä¿®å¤** - ç»Ÿä¸€æ ‡ç­¾å¤§å°å†™å¤„ç†
4. **ä»£ç å®¡æŸ¥ä¿®å¤** - è§£å†³Seriesè®¿é—®ã€å¼‚å¸¸å¤„ç†ã€æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–

æœªå®æ–½çš„æ¨¡å—ï¼ˆé™ä½ä¼˜å…ˆçº§ï¼‰ï¼š
- ~~MMRåˆ†æ•°å±•ç¤ºä¿®å¤~~ - å‰ç«¯ä¸å±•ç¤ºscoreå­—æ®µ
- ~~æ¢ç´¢æœºåˆ¶è°ƒæ•´~~ - ä¸å½±å“æ ¸å¿ƒé—®é¢˜
- ~~ç¼“å­˜æ—¶é—´æ¡¶~~ - æ¶æ„çº§åˆ«ä¿®æ”¹ï¼Œç‹¬ç«‹ä»»åŠ¡å¤„ç†

---

## Technical Details

### å…³é”®æ–‡ä»¶
- `app/main.py`
  - `_apply_mmr_reranking()` - MMRé‡æ’é€»è¾‘ï¼ˆline 1138ï¼‰
  - `_build_response_items()` - æ„å»ºAPIå“åº”ï¼ˆline 1246ï¼‰
  - `_apply_ranking_with_circuit_breaker()` - æ’åºåˆ†æ•°åº”ç”¨ï¼ˆline 2217ï¼‰
  - `DEFAULT_CHANNEL_WEIGHTS` - æ¸ é“æƒé‡é…ç½®ï¼ˆline 183ï¼‰

### æ•°æ®åˆ†æ
ä»ç”Ÿäº§ç¯å¢ƒæ¡ˆä¾‹ï¼ˆdataset_id=13003, user_id=1997ï¼‰ï¼š
```
æ€»æ¨èæ•°ï¼š30
æ­£åˆ†ï¼š10ä¸ªï¼ˆ2.057 ~ 0.424ï¼‰
è´Ÿåˆ†ï¼š16ä¸ªï¼ˆ-0.320 ~ -2.887ï¼‰- 53% ğŸ”´
æ¢ç´¢ï¼š4ä¸ªï¼ˆå›ºå®š0.5ï¼‰- 13%

è´Ÿåˆ†æ¥æºåˆ†å¸ƒï¼š
- Popular: 6ä¸ªï¼ˆ-2.57 ~ -2.83ï¼‰
- Behavior/UserCF: 7ä¸ªï¼ˆ-0.32 ~ -2.89ï¼‰
- Content+Vector: 2ä¸ªï¼ˆ-0.78, -2.48ï¼‰
- Price: 1ä¸ªï¼ˆ-2.79ï¼‰
```

### ä¾èµ–å…³ç³»
- æ¨¡å—1å’Œ2æ— ä¾èµ–ï¼Œå¯å¹¶è¡Œå®æ–½
- æ¨¡å—3éœ€è¦è§‚å¯Ÿæ¨¡å—2æ•ˆæœåå†³å®š
- æ¨¡å—4ä¼˜å…ˆçº§æœ€ä½ï¼Œå¯å»¶å

## Context Manifest

### ç³»ç»Ÿæ¦‚è§ˆï¼šæ¨èæµç¨‹å®Œæ•´é“¾è·¯

**æ¨èç³»ç»Ÿæ ¸å¿ƒæµç¨‹ï¼ˆä»ç”¨æˆ·è¯·æ±‚åˆ°è¿”å›ç»“æœï¼‰**ï¼š

å½“ç”¨æˆ·è¯·æ±‚æ¨èï¼ˆ`GET /recommend/detail/{dataset_id}?user_id={user_id}&limit=10`ï¼‰æ—¶ï¼Œç³»ç»Ÿç»å†ä»¥ä¸‹é˜¶æ®µï¼š

1. **å¤šæ¸ é“å¬å›é˜¶æ®µï¼ˆRecallï¼‰** - ä»ä¸åŒæ¥æºæ”¶é›†å€™é€‰item
2. **åˆ†æ•°èåˆé˜¶æ®µï¼ˆScore Fusionï¼‰** - åˆå¹¶å¤šæ¸ é“åˆ†æ•°
3. **ä¸ªæ€§åŒ–é˜¶æ®µï¼ˆPersonalizationï¼‰** - åŸºäºç”¨æˆ·å†å²è°ƒæ•´
4. **æ’åºé˜¶æ®µï¼ˆRankingï¼‰** - LightGBM rankeræ‰“åˆ†ï¼ˆ**è¿™é‡Œäº§ç”Ÿè´Ÿåˆ†**ï¼‰
5. **MMRé‡æ’é˜¶æ®µï¼ˆMMR Rerankingï¼‰** - å¤šæ ·æ€§ä¼˜åŒ–ï¼ˆ**è¿™é‡Œå¯¼è‡´scoreå±•ç¤ºæ··ä¹±**ï¼‰
6. **æ¢ç´¢é˜¶æ®µï¼ˆExplorationï¼‰** - epsilon-greedyæ¢ç´¢
7. **æ„å»ºå“åº”é˜¶æ®µï¼ˆResponse Buildingï¼‰** - è¿”å›APIç»“æœ

**é—®é¢˜å‘ç”Ÿä½ç½®**ï¼š
- **è´Ÿåˆ†é—®é¢˜**ï¼šå‘ç”Ÿåœ¨ç¬¬4æ­¥æ’åºé˜¶æ®µï¼ŒLightGBM rankerè¾“å‡ºè´Ÿåˆ†
- **scoreå±•ç¤ºæ··ä¹±**ï¼šå‘ç”Ÿåœ¨ç¬¬7æ­¥ï¼ŒMMRé‡æ’åä½¿ç”¨åŸå§‹å¬å›åˆ†æ•°è€ŒéMMRåˆ†æ•°

### æ·±å…¥å‰–æï¼šè´Ÿåˆ†äº§ç”Ÿæœºåˆ¶

**LightGBM Rankerçš„è´Ÿåˆ†æ¥æº**

ç³»ç»Ÿä½¿ç”¨LightGBM LambdaRankæ¨¡å‹ï¼ˆ`objective="lambdarank"`, `metric="ndcg"`ï¼‰è¿›è¡Œæ’åºã€‚è¯¥æ¨¡å‹è¾“å‡ºçš„æ˜¯**åŸå§‹é¢„æµ‹åˆ†æ•°ï¼ˆraw prediction scoresï¼‰**ï¼Œä¸æ˜¯å½’ä¸€åŒ–çš„æ¦‚ç‡å€¼ã€‚

**è®­ç»ƒæµç¨‹**ï¼ˆ`pipeline/train_models.py`ï¼‰ï¼š

```python
# Line 1044: LambdaRanké…ç½®
base_params = {
    "objective": "lambdarank",  # åŸºäºæ’åºå¯¹çš„å­¦ä¹ ç›®æ ‡
    "metric": "ndcg",           # ä¼˜åŒ–NDCG@10æŒ‡æ ‡
    "n_estimators": 300,
    "learning_rate": 0.05,
    "num_leaves": 63,
    # ... å…¶ä»–å‚æ•°
}

# è®­ç»ƒæ•°æ®ï¼šæ¯ä¸ªrequestä½œä¸ºä¸€ä¸ªquery group
# - request_id: ç”¨æˆ·çš„ä¸€æ¬¡æ¨èè¯·æ±‚
# - dataset_id: å€™é€‰item
# - label: 0/1ï¼ˆç‚¹å‡»ï¼‰æˆ–è¿ç»­å€¼ï¼ˆCTR + CVR_weight * CVRï¼‰
# - group_sizes: æ¯ä¸ªrequestæœ‰å¤šå°‘ä¸ªå€™é€‰ï¼ˆç”¨äºLambdaRankçš„pairwise learningï¼‰

ranker = LGBMRanker(**params)
ranker.fit(X_train, y_train, group=group_train)  # groupå®šä¹‰äº†æ’åºè¾¹ç•Œ
```

**ä¸ºä»€ä¹ˆä¼šäº§ç”Ÿè´Ÿåˆ†**ï¼š

LightGBM LambdaRankçš„é¢„æµ‹è¾“å‡ºæ˜¯**æœªç»å½’ä¸€åŒ–çš„å†³ç­–å€¼**ï¼ˆç±»ä¼¼çº¿æ€§å›å½’çš„y_predï¼‰ï¼ŒèŒƒå›´å¯ä»¥æ˜¯(-âˆ, +âˆ)ã€‚è´Ÿåˆ†è¡¨ç¤ºæ¨¡å‹è®¤ä¸ºè¯¥itemè´¨é‡ä½äº"åŸºçº¿æ°´å¹³"ï¼š

- **æ­£åˆ†**ï¼šæ¨¡å‹é¢„æµ‹è¯¥itemè´¨é‡é«˜äºå¹³å‡æ°´å¹³ï¼Œç”¨æˆ·æœ‰è¾ƒé«˜æ¦‚ç‡ç‚¹å‡»/è½¬åŒ–
- **è´Ÿåˆ†**ï¼šæ¨¡å‹é¢„æµ‹è¯¥itemè´¨é‡ä½äºå¹³å‡æ°´å¹³ï¼Œç”¨æˆ·ç‚¹å‡»/è½¬åŒ–æ¦‚ç‡ä½
- **æ¥è¿‘0**ï¼šæ¥è¿‘å¹³å‡è´¨é‡æ°´å¹³

**è´Ÿåˆ†çš„è¯­ä¹‰åˆç†æ€§**ï¼š

è´Ÿåˆ†æœ¬èº«æ˜¯åˆç†çš„æ¨¡å‹è¾“å‡ºï¼Œç”¨äºåŒºåˆ†å¥½åitemã€‚ä½†**å±•ç¤ºç»™ç”¨æˆ·æ—¶ä¼šé€ æˆå›°æ‰°**ï¼Œå› ä¸ºï¼š
1. ç”¨æˆ·æœŸæœ›scoreæ˜¯è´¨é‡åˆ†æ•°ï¼ˆè¶Šé«˜è¶Šå¥½ï¼Œ0-1èŒƒå›´ï¼‰
2. è´Ÿåˆ†æš—ç¤º"è´¨é‡å·®"ã€"ä¸æ¨è"ï¼Œé‚£ä¸ºä»€ä¹ˆè¿˜æ¨èï¼Ÿ
3. ä¸å…¶ä»–å¬å›æ¸ é“çš„å½’ä¸€åŒ–åˆ†æ•°ï¼ˆ0-1ï¼‰ä¸ä¸€è‡´

### æ·±å…¥å‰–æï¼šå¤šæ¸ é“å¬å›ä¸åˆ†æ•°èŒƒå›´

**å››å¤§å¬å›æ¸ é“çš„åŸå§‹åˆ†æ•°èŒƒå›´**ï¼š

```python
# app/main.py Line 1611-1700: _combine_scores_with_weights

# 1. Behaviorå¬å›ï¼ˆååŒè¿‡æ»¤ï¼Œitem-itemç›¸ä¼¼åº¦ï¼‰
# åŸå§‹åˆ†æ•°ï¼šä½™å¼¦ç›¸ä¼¼åº¦æˆ–Jaccardç›¸ä¼¼åº¦ [0, 1]
# å½’ä¸€åŒ–åï¼šMin-Max scaling â†’ [0, 1]
# æƒé‡ï¼š1.2 (DEFAULT_CHANNEL_WEIGHTS["behavior"])

# 2. Contentå¬å›ï¼ˆåŸºäºæ ‡ç­¾/æè¿°çš„TF-IDFç›¸ä¼¼åº¦ï¼‰
# åŸå§‹åˆ†æ•°ï¼šä½™å¼¦ç›¸ä¼¼åº¦ [0.2, 0.9]
# å½’ä¸€åŒ–åï¼šMin-Max scaling â†’ [0, 1]
# æƒé‡ï¼š1.0

# 3. Vectorå¬å›ï¼ˆSBERTè¯­ä¹‰å‘é‡ç›¸ä¼¼åº¦ï¼‰
# åŸå§‹åˆ†æ•°ï¼šä½™å¼¦ç›¸ä¼¼åº¦ [15, 22]ï¼ˆæœªå½’ä¸€åŒ–ï¼Œå› æ­¤rangeå¤§ï¼‰
# å½’ä¸€åŒ–åï¼šMin-Max scaling â†’ [0, 1]
# æƒé‡ï¼š0.8

# 4. Popularå¬å›ï¼ˆå…¨å±€çƒ­é—¨æ¦œå•ï¼‰
# åŸå§‹åˆ†æ•°ï¼šçº¿æ€§è¡°å‡ popular_scores[item_id] = 1.0 - (idx / len(popular)) * 0.9
#   - ç¬¬1ä¸ªitem: 1.0
#   - æœ€åä¸€ä¸ª: 0.1
# æƒé‡ï¼š0.1ï¼ˆLine 1696ï¼‰
```

**åˆ†æ•°èåˆæœºåˆ¶**ï¼ˆå·²åšå½’ä¸€åŒ–ï¼‰ï¼š

```python
# Line 1585-1609: _normalize_channel_scores
# æ¯ä¸ªæ¸ é“ç‹¬ç«‹å½’ä¸€åŒ–åˆ°[0, 1]ï¼Œé˜²æ­¢vectorçš„15-22å‹åˆ¶contentçš„0.2-0.9

normalized_score = (score - min_score) / (max_score - min_score)
final_score = normalized_score * channel_weight

# å¤šæ¸ é“ç´¯åŠ ï¼ˆå…è®¸overlapï¼‰
scores[item_id] += normalized_score * weight
```

**æ’åºé˜¶æ®µçš„åˆ†æ•°å˜æ¢**ï¼š

```python
# Line 2217-2246: _apply_ranking_with_circuit_breaker

# 1. å¬å›åˆ†æ•°ï¼ˆå·²å½’ä¸€åŒ–ï¼Œæ­£æ•°ï¼‰ï¼šscores = {dataset_id: 0.5~2.0}
# 2. LightGBM rankeré¢„æµ‹ï¼šprob = ranker.predict(features) â†’ (-3, +3)
# 3. æ–°é²œåº¦åŠ æƒï¼šfreshness_boost = 0.8 + 0.2 * freshness_score
# 4. æœ€ç»ˆåˆ†æ•°æ›´æ–°ï¼š
scores[dataset_id] += prob * freshness_boost  # ç´¯åŠ ï¼

# ç¤ºä¾‹è®¡ç®—ï¼š
# - å¬å›åˆ†æ•°ï¼š0.5ï¼ˆPopularæ¸ é“ï¼Œæƒé‡0.1ï¼‰
# - Rankeré¢„æµ‹ï¼š-2.8ï¼ˆæ¨¡å‹è®¤ä¸ºè´¨é‡æå·®ï¼‰
# - æ–°é²œåº¦ï¼š0.8ï¼ˆè€å†…å®¹ï¼‰
# - æœ€ç»ˆåˆ†æ•°ï¼š0.5 + (-2.8 * 0.8) = 0.5 - 2.24 = -1.74 âŒè´Ÿåˆ†ï¼
```

**ä¸ºä»€ä¹ˆPopularå¬å›å®¹æ˜“äº§ç”Ÿè´Ÿåˆ†**ï¼š

Popularå¬å›çš„é—®é¢˜åœ¨äº**ç¼ºä¹ä¸Šä¸‹æ–‡ç›¸å…³æ€§**ï¼š
- å®ƒæ˜¯å…¨å±€çƒ­é—¨æ¦œå•ï¼ˆ`models/top_items.json`ï¼‰ï¼Œä¸è€ƒè™‘target_datasetçš„ç±»åˆ«/æ ‡ç­¾
- ä¾‹å¦‚ï¼šç”¨æˆ·æµè§ˆ"æ•°æ®åˆ†æå·¥å…·"ï¼ŒPopularå¬å›äº†"é¼ æ ‡æŒ‡é’ˆçš®è‚¤"ï¼ˆå…¨å±€çƒ­é—¨ä½†å®Œå…¨ä¸ç›¸å…³ï¼‰
- LightGBM rankeråŸºäºç‰¹å¾åˆ¤æ–­ç›¸å…³æ€§å·®ï¼Œç»™äºˆé‡åº¦æƒ©ç½šï¼ˆ-2.5 ~ -2.8ï¼‰
- Popularå¬å›æƒé‡ä½ï¼ˆ0.1ï¼‰ï¼Œåˆå§‹åˆ†æ•°0.1~0.5ï¼Œrankeræƒ©ç½šåå˜æˆè´Ÿåˆ†

**Popularå¬å›çš„å®ç°**ï¼ˆæ— è¿‡æ»¤ï¼‰ï¼š

```python
# Line 1684-1697
popular_scores = {}
for idx, item_id in enumerate(popular):  # popularæ˜¯é™æ€æ¦œå•List[int]
    if item_id == target_id or item_id in scores:
        continue
    popular_scores[item_id] = 1.0 - (idx / max(len(popular), 1)) * 0.9  # çº¿æ€§è¡°å‡
    if len(popular_scores) >= limit * 5:
        break

for item_id, norm_score in popular_scores.items():
    scores[item_id] = norm_score * weights.get("popular", 0.01)  # æƒé‡0.1
    reasons[item_id] = "popular"
```

**Popularæ¦œå•æ„å»º**ï¼ˆ`pipeline/train_models.py`ï¼‰ï¼š

```python
# ç®€å•æŒ‰interaction_counté™åºæ’åºï¼Œå–top 50
top_items = (
    dataset_stats[["dataset_id", "interaction_count"]]
    .sort_values("interaction_count", ascending=False)
    .head(50)["dataset_id"]
    .tolist()
)
save_json(top_items, MODELS_DIR / "top_items.json")
```

æ²¡æœ‰ä»»ä½•ç±»åˆ«ã€æ ‡ç­¾ã€åœºæ™¯çš„è€ƒè™‘ï¼Œçº¯ç²¹å…¨å±€çƒ­é—¨ï¼

### æ·±å…¥å‰–æï¼šMMRé‡æ’ä¸åˆ†æ•°å±•ç¤ºæ··ä¹±

**MMRï¼ˆMaximal Marginal Relevanceï¼‰ç®—æ³•åŸç†**ï¼š

MMRç”¨äºå¹³è¡¡**ç›¸å…³æ€§ï¼ˆRelevanceï¼‰**å’Œ**å¤šæ ·æ€§ï¼ˆDiversityï¼‰**ï¼Œé¿å…æ¨èç»“æœè¿‡äºåŒè´¨åŒ–ã€‚

```python
# Line 1138-1201: _apply_mmr_reranking

# è¾“å…¥ï¼š
# - scores: {dataset_id: raw_score}  ä¾‹å¦‚ {111: 0.33, 13185: -0.78}
# - dataset_tags: {dataset_id: [tag1, tag2, ...]}
# - lambda_param: 0.7ï¼ˆç›¸å…³æ€§æƒé‡ï¼Œ1.0=çº¯ç›¸å…³æ€§ï¼Œ0.0=çº¯å¤šæ ·æ€§ï¼‰

# æ­¥éª¤1ï¼šå½’ä¸€åŒ–åŸå§‹åˆ†æ•°åˆ°[0, 1]
max_score = max(scores.values())  # 0.33
min_score = min(scores.values())  # -0.78
score_range = max_score - min_score  # 1.11

normalized_scores = {
    111: (0.33 - (-0.78)) / 1.11 = 1.0,
    13185: (-0.78 - (-0.78)) / 1.11 = 0.0,
}

# æ­¥éª¤2ï¼šè¿­ä»£é€‰æ‹©ï¼ˆè´ªå¿ƒç®—æ³•ï¼‰
selected = []
while len(selected) < limit:
    for candidate in candidates:
        relevance = normalized_scores[candidate]  # å½’ä¸€åŒ–åçš„ç›¸å…³æ€§

        # è®¡ç®—ä¸å·²é€‰itemçš„æœ€å¤§ç›¸ä¼¼åº¦ï¼ˆåŸºäºJaccardæ ‡ç­¾ç›¸ä¼¼åº¦ï¼‰
        max_sim = max(
            jaccard_similarity(tags[candidate], tags[s])
            for s in selected
        ) if selected else 0.0

        # MMRåˆ†æ•° = Î» * ç›¸å…³æ€§ - (1-Î») * æœ€å¤§ç›¸ä¼¼åº¦
        mmr_score = lambda_param * relevance - (1 - lambda_param) * max_sim

    # é€‰æ‹©MMRåˆ†æ•°æœ€é«˜çš„candidate
    best = max(mmr_scores.items(), key=lambda x: x[1])[0]
    selected.append(best)

# è¾“å‡ºï¼šranked_ids = [13185, 111, ...]ï¼ˆMMRé¡ºåºï¼Œå¯èƒ½ä¸åŸå§‹åˆ†æ•°é¡ºåºä¸åŒï¼‰
```

**ç¤ºä¾‹è¯´æ˜**ï¼š

å‡è®¾åŸå§‹åˆ†æ•°ï¼š
- Item A: score=0.33, tags=["æ•°æ®åˆ†æ", "å¯è§†åŒ–"]
- Item B: score=-0.78, tags=["å›¾è¡¨", "ä»ªè¡¨ç›˜", "æ•°æ®åˆ†æ"]

å½’ä¸€åŒ–åï¼š
- Item A: relevance=1.0
- Item B: relevance=0.0

ç¬¬ä¸€è½®é€‰æ‹©ï¼š
- Item A: mmr_score = 0.7 * 1.0 - 0 = 0.7
- Item B: mmr_score = 0.7 * 0.0 - 0 = 0.0
- **é€‰æ‹©Item A**

ç¬¬äºŒè½®é€‰æ‹©ï¼š
- Item B:
  - jaccard_sim(B, A) = |{æ•°æ®åˆ†æ}| / |{æ•°æ®åˆ†æ, å¯è§†åŒ–, å›¾è¡¨, ä»ªè¡¨ç›˜}| = 1/4 = 0.25
  - mmr_score = 0.7 * 0.0 - 0.3 * 0.25 = -0.075

å‡è®¾æœ‰Item Cï¼ˆscore=-0.5, tags=["æœºå™¨å­¦ä¹ ", "é¢„æµ‹"]ï¼‰ï¼š
- Item C:
  - jaccard_sim(C, A) = 0ï¼ˆæ— å…±åŒæ ‡ç­¾ï¼‰
  - mmr_score = 0.7 * 0.25 - 0.3 * 0 = 0.175
- **é€‰æ‹©Item Cï¼ˆå¤šæ ·æ€§æ›´å¥½ï¼Œå³ä½¿åŸå§‹åˆ†æ•°ä½ï¼‰**

æœ€ç»ˆæ’åºï¼š`[A, C, B, ...]` ä½†å®ƒä»¬çš„åŸå§‹åˆ†æ•°æ˜¯`[0.33, -0.5, -0.78]`ï¼

**åˆ†æ•°å±•ç¤ºæ··ä¹±çš„æ ¹æœ¬åŸå› **ï¼š

```python
# Line 1246-1320: _build_response_items

# æ­¥éª¤1ï¼šMMRé‡æ’ï¼ˆè¿”å›æ–°çš„é¡ºåºï¼‰
if apply_mmr and dataset_tags:
    ranked_ids = _apply_mmr_reranking(
        candidate_scores,  # åŸå§‹åˆ†æ•°å­—å…¸
        dataset_tags,
        lambda_param=mmr_lambda,
        limit=limit,
    )
    # ranked_ids = [13185, 111, 333, ...]ï¼ˆMMRé¡ºåºï¼‰
else:
    # é™åºæ’åº
    ranked_ids = sorted(candidate_scores.items(), key=lambda kv: kv[1], reverse=True)

# æ­¥éª¤2ï¼šæ„å»ºå“åº”ï¼ˆé—®é¢˜å‡ºåœ¨è¿™é‡Œï¼ï¼‰
for dataset_id in ranked_ids:  # æŒ‰MMRé¡ºåºéå†
    score = candidate_scores.get(dataset_id, 0.5)  # ä½¿ç”¨åŸå§‹åˆ†æ•°ï¼âŒ

    result.append(
        RecommendationItem(
            dataset_id=dataset_id,
            score=score,  # å±•ç¤ºåŸå§‹åˆ†æ•°ï¼Œä½†é¡ºåºæ˜¯MMRçš„
            reason=reason,
        )
    )

# è¿”å›ç»“æœï¼š
# [
#   {dataset_id: 13185, score: -0.78, reason: "behavior"},  # MMRé€‰äº†å®ƒï¼ˆå¤šæ ·æ€§å¥½ï¼‰
#   {dataset_id: 111, score: 0.33, reason: "content"},     # ä½†scoreæ˜¯ä¹±çš„ï¼
# ]
```

**ç”¨æˆ·çœ‹åˆ°çš„æ··ä¹±ç°è±¡**ï¼š

```
æ¨èç»“æœï¼ˆé™åºå±•ç¤ºï¼‰ï¼š
1. Item 13185 - score: -0.78 â¬…ï¸ è´Ÿåˆ†æ’åœ¨ç¬¬1ï¼
2. Item 333   - score: -0.50
3. Item 111   - score: 0.33  â¬…ï¸ æ­£åˆ†æ’åœ¨ç¬¬3ï¼
4. Item 555   - score: 0.20
```

ç”¨æˆ·ç–‘æƒ‘ï¼š"ä¸ºä»€ä¹ˆè´Ÿåˆ†æ’åœ¨æ­£åˆ†å‰é¢ï¼Ÿæ¨èç³»ç»Ÿåäº†å—ï¼Ÿ"

**å®é™…åŸå› **ï¼šMMRè®¤ä¸º13185è™½ç„¶åˆ†æ•°ä½ï¼Œä½†å¤šæ ·æ€§ä»·å€¼é«˜ï¼Œæ‰€ä»¥æ’åœ¨å‰é¢ã€‚ä½†å±•ç¤ºçš„scoreå­—æ®µæ˜¯åŸå§‹åˆ†æ•°ï¼Œæ²¡æœ‰åæ˜ MMRçš„å†³ç­–ã€‚

### æ·±å…¥å‰–æï¼šæ¢ç´¢æœºåˆ¶ï¼ˆExplorationï¼‰

**Epsilon-Greedyæ¢ç´¢ç­–ç•¥**ï¼š

```python
# Line 1204-1243: _apply_exploration

# å‚æ•°ï¼š
# - ranked_ids: å·²æ’åºçš„itemåˆ—è¡¨ï¼ˆMMRåï¼‰
# - all_dataset_ids: å…¨é‡itemæ± 
# - epsilon: æ¢ç´¢ç‡ï¼ˆ0.15 = 15%ï¼‰

n_total = len(ranked_ids)  # 30
n_explore = int(n_total * epsilon)  # 30 * 0.15 = 4ï¼ˆå‘ä¸‹å–æ•´ï¼‰
n_exploit = n_total - n_explore  # 26

# ä¿ç•™å‰26ä¸ªç¡®å®šæ€§item
exploit_ids = ranked_ids[:26]

# ä»æœªè¢«é€‰ä¸­çš„itemä¸­éšæœºé‡‡æ ·4ä¸ª
explore_pool = all_dataset_ids - set(exploit_ids)
explore_ids = random.sample(explore_pool, 4)

# è¿”å›ï¼š[ç¡®å®šæ€§item...] + [æ¢ç´¢item...]
return exploit_ids + explore_ids
```

**æ¢ç´¢itemçš„åˆ†æ•°å¤„ç†**ï¼š

```python
# Line 1302-1318: _build_response_items

for dataset_id in ranked_ids:
    # æ¢ç´¢itemå¯èƒ½ä¸åœ¨candidate_scoresä¸­
    score = candidate_scores.get(dataset_id, 0.5)  # é»˜è®¤0.5
    reason = reasons.get(dataset_id, "exploration" if dataset_id not in candidate_scores else "unknown")

    result.append(
        RecommendationItem(
            dataset_id=dataset_id,
            score=score,  # æ¢ç´¢itemå›ºå®š0.5
            reason=reason,  # "exploration"
        )
    )
```

**æ¢ç´¢itemå±•ç¤ºé—®é¢˜**ï¼š

- æ¢ç´¢itemå›ºå®šscore=0.5ï¼Œæ’å…¥åœ¨åˆ—è¡¨æœ€å
- å¦‚æœå‰é¢æœ‰è´Ÿåˆ†itemï¼ˆ-0.3 ~ -2.8ï¼‰ï¼Œæ¢ç´¢itemä¼šæ’åœ¨è´Ÿåˆ†åé¢
- è§†è§‰ä¸Šï¼š"ä¸ºä»€ä¹ˆ0.5åˆ†æ’åœ¨-2.5åé¢ï¼Ÿ"

### æŠ€æœ¯å®ç°ç»†èŠ‚

#### 1. æ¨èæµç¨‹ä»£ç ç»“æ„

**ä¸»å…¥å£å‡½æ•°**ï¼ˆ`app/main.py Line 2950-3298`ï¼‰ï¼š

```python
@app.get("/recommend/detail/{dataset_id}", response_model=RecommendationResponse)
async def recommend_for_detail(
    request: Request,
    dataset_id: int,
    user_id: Optional[int] = None,
    limit: int = Query(10, ge=1, le=50),
) -> RecommendationResponse:

    # æ ¸å¿ƒè®¡ç®—é€»è¾‘
    async def _compute():
        # 1. å¬å›+èåˆ
        scores, reasons = _combine_scores_with_weights(
            dataset_id,
            local_bundle.behavior,
            local_bundle.content,
            local_bundle.vector,
            local_bundle.popular,
            limit,
            effective_weights,
        )

        # 2. ä¸ªæ€§åŒ–
        _apply_personalization(user_id, scores, reasons, state, ...)

        # 3. å¤šæ¸ é“å¢å¼º
        _augment_with_multi_channel(state, target_id=dataset_id, scores=scores, ...)

        # 4. æ’åºï¼ˆLightGBM rankerï¼‰
        await _call_blocking(
            partial(
                _apply_ranking,
                scores, reasons,
                local_bundle.rank_model,
                state.raw_features,
                ...
            ),
            endpoint=endpoint,
            operation="model_inference",
            timeout=TimeoutManager.get_timeout("model_inference"),
        )

        # 5. MMRé‡æ’ + æ¢ç´¢ + æ„å»ºå“åº”
        mmr_lambda = _compute_mmr_lambda(endpoint=endpoint, request_context=request_context)
        items = _build_response_items(
            scores, reasons, limit, state.metadata,
            dataset_tags=state.dataset_tags,
            apply_mmr=True,
            mmr_lambda=mmr_lambda,
            apply_exploration=True,
            exploration_epsilon=0.15,
            all_dataset_ids=set(state.metadata.keys()),
        )

        return items, reasons, variant, run_id, effective_weights

    items, reasons, variant, run_id, applied_channel_weights = await _compute()

    return RecommendationResponse(
        dataset_id=dataset_id,
        recommendations=items[:limit],
        request_id=request_id,
        algorithm_version=run_id,
        variant=variant,
    )
```

#### 2. å…³é”®æ•°æ®ç»“æ„

**RecommendationItem**ï¼ˆLine 575-582ï¼‰ï¼š

```python
class RecommendationItem(BaseModel):
    dataset_id: int
    title: Optional[str]
    price: Optional[float]
    cover_image: Optional[str]
    score: float  # è¿™ä¸ªå­—æ®µå¯¼è‡´äº†æ··ä¹±ï¼
    reason: str   # å¬å›æ¸ é“ï¼š"behavior", "content", "popular+rank", "exploration"
```

**ModelBundle**ï¼ˆLine 111-119ï¼‰ï¼š

```python
@dataclass
class ModelBundle:
    behavior: Dict[int, Dict[int, float]]  # {source_id: {neighbor_id: similarity}}
    content: Dict[int, Dict[int, float]]   # åŒä¸Š
    vector: Dict[int, List[Dict[str, float]]]  # {source_id: [{dataset_id, score}, ...]}
    popular: List[int]  # [13419, 13116, ...]ï¼ˆå…¨å±€çƒ­é—¨æ¦œå•ï¼Œæ— è¿‡æ»¤ï¼‰
    rank_model: Optional[Pipeline]  # LightGBM rankeræˆ–Pipeline
    run_id: Optional[str]  # æ¨¡å‹ç‰ˆæœ¬ID
```

#### 3. é…ç½®å‚æ•°

**æ¸ é“æƒé‡**ï¼ˆLine 183-188ï¼‰ï¼š

```python
DEFAULT_CHANNEL_WEIGHTS = {
    "behavior": 1.2,  # ç”¨æˆ·ååŒè¿‡æ»¤
    "content": 1.0,   # å†…å®¹ç›¸ä¼¼åº¦
    "vector": 0.8,    # è¯­ä¹‰å‘é‡
    "popular": 0.1,   # å…¨å±€çƒ­é—¨ï¼ˆæƒé‡ä½ï¼Œä½†ä»ä¼šå¬å›ï¼‰
}
```

**MMRå‚æ•°**ï¼š

```python
# Line 3119-3125
mmr_lambda = _compute_mmr_lambda(endpoint=endpoint, request_context=request_context)
# é»˜è®¤å€¼ï¼š0.7ï¼ˆ70%ç›¸å…³æ€§ + 30%å¤šæ ·æ€§ï¼‰

# MMRåœ¨ _build_response_items ä¸­è°ƒç”¨ï¼š
apply_mmr=True,
mmr_lambda=mmr_lambda,  # 0.7
```

**æ¢ç´¢å‚æ•°**ï¼š

```python
# Line 3126-3128
apply_exploration=True,
exploration_epsilon=0.15,  # 15%æ¢ç´¢ç‡
all_dataset_ids=set(state.metadata.keys()),  # å…¨é‡æ± 
```

#### 4. æ’åºæ¨¡å‹ç‰¹å¾

**ç‰¹å¾ç±»å‹**ï¼ˆ`pipeline/train_models.py`ï¼‰ï¼š

- **Itemç‰¹å¾**ï¼šprice, price_log, description_length, tag_count, popularity_rank, price_bucket, text_pca_0~9ï¼ˆSBERTé™ç»´ï¼‰, interaction_count, total_weight
- **ç»Ÿè®¡ç‰¹å¾**ï¼šslot_total_exposures, slot_total_clicks, slot_mean_ctr, slot_mean_cvr
- **Requestç‰¹å¾**ï¼šscoreï¼ˆå¬å›åˆ†æ•°ï¼‰, positionï¼ˆåˆå§‹æ’åºä½ç½®ï¼‰, channelï¼ˆå¬å›æ¸ é“ï¼‰, channel_weight, endpoint, variant, experiment_variant
- **Userç‰¹å¾**ï¼ˆå¦‚æœæœ‰ï¼‰ï¼šuser_interaction_count, user_avg_price, user_tag_preference_*

**æ¨¡å‹è¾“å‡º**ï¼š

```python
# Line 2197-2213: _predict_rank_scores

if isinstance(rank_model, dict) and rank_model.get("type") == "lightgbm_ranker":
    prepared = _prepare_ranker_features(rank_model, features)
    scores = rank_model["model"].predict(prepared)  # LGBMRanker.predict()
    return pd.Series(scores, index=features.index, dtype=float)
    # è¿”å›ï¼šraw prediction scoresï¼ŒèŒƒå›´(-âˆ, +âˆ)
```

### ä¿®å¤æ–¹æ¡ˆæŠ€æœ¯è·¯å¾„

#### æ–¹æ¡ˆAï¼šå±•ç¤ºåºå·åˆ†æ•°ï¼ˆæ¨èï¼Œç®€å•å¿«é€Ÿï¼‰

**åŸç†**ï¼šç”¨ä½ç½®åºå·ç”Ÿæˆé€’å‡åˆ†æ•°ï¼Œä¿è¯é™åºè¯­ä¹‰ã€‚

**å®ç°ä½ç½®**ï¼š`app/main.py Line 1302-1318`

```python
# ä¿®æ”¹å‰
for dataset_id in ranked_ids:
    score = candidate_scores.get(dataset_id, 0.5)

# ä¿®æ”¹å
for idx, dataset_id in enumerate(ranked_ids):
    if apply_mmr:
        # ä½ç½®åˆ†æ•°ï¼š1.0ï¼ˆç¬¬1åï¼‰ â†’ 0.5ï¼ˆæœ€å1åï¼‰
        score = 1.0 - (idx / len(ranked_ids)) * 0.5
    else:
        score = candidate_scores.get(dataset_id, 0.5)
```

**ä¼˜ç‚¹**ï¼š
- ç®€å•ï¼Œ5è¡Œä»£ç 
- åˆ†æ•°ä¸¥æ ¼é™åºï¼Œç”¨æˆ·ä¸å›°æƒ‘
- ä¸æ”¹å˜APIç»“æ„

**ç¼ºç‚¹**ï¼š
- ä¸¢å¤±åŸå§‹åˆ†æ•°ä¿¡æ¯ï¼ˆä½†ç”¨æˆ·æœ¬æ¥ä¹Ÿä¸å…³å¿ƒï¼‰
- æ‰€æœ‰itemåˆ†æ•°æ‹‰å¹³ï¼ˆ0.5-1.0ï¼‰ï¼Œæ— æ³•åŒºåˆ†è´¨é‡å·®è·

#### æ–¹æ¡ˆBï¼šè¿”å›å®é™…MMRåˆ†æ•°ï¼ˆç²¾ç¡®ï¼Œå¤æ‚ï¼‰

**åŸç†**ï¼šä¿®æ”¹MMRå‡½æ•°è¿”å›è®¡ç®—å‡ºçš„MMRåˆ†æ•°ã€‚

**å®ç°ä½ç½®**ï¼š
1. `_apply_mmr_reranking` è¿”å›`(selected, mmr_scores_dict)`
2. `_build_response_items` ä½¿ç”¨MMRåˆ†æ•°

```python
# Line 1138-1201: _apply_mmr_reranking ä¿®æ”¹
def _apply_mmr_reranking(...) -> Tuple[List[int], Dict[int, float]]:
    selected = []
    mmr_scores_final = {}

    while len(selected) < limit and candidates:
        mmr_scores = {}
        for candidate in candidates:
            # ... MMRè®¡ç®—
            mmr_scores[candidate] = lambda_param * relevance - (1 - lambda_param) * max_sim

        best = max(mmr_scores.items(), key=lambda x: x[1])[0]
        selected.append(best)
        mmr_scores_final[best] = mmr_scores[best]  # ä¿å­˜MMRåˆ†æ•°
        candidates.remove(best)

    return selected, mmr_scores_final

# Line 1280-1286: _build_response_items è°ƒç”¨ä¿®æ”¹
if apply_mmr and dataset_tags:
    ranked_ids, mmr_scores = _apply_mmr_reranking(...)  # æ¥æ”¶ä¸¤ä¸ªè¿”å›å€¼
else:
    ranked_ids = ...
    mmr_scores = {}

# Line 1305
score = mmr_scores.get(dataset_id) or candidate_scores.get(dataset_id, 0.5)
```

**ä¼˜ç‚¹**ï¼š
- ç²¾ç¡®åæ˜ MMRå†³ç­–
- åˆ†æ•°æœ‰å®é™…å«ä¹‰ï¼ˆç›¸å…³æ€§-å¤šæ ·æ€§æƒè¡¡ï¼‰

**ç¼ºç‚¹**ï¼š
- MMRåˆ†æ•°å¯èƒ½æ˜¯è´Ÿæ•°ï¼ˆrelevance=0, max_sim=0.5 â†’ 0.7*0 - 0.3*0.5 = -0.15ï¼‰
- éœ€è¦ä¿®æ”¹å¤šä¸ªå‡½æ•°ç­¾å
- å¤æ‚åº¦é«˜

#### æ–¹æ¡ˆCï¼šè¿‡æ»¤è´Ÿåˆ†ï¼ˆç¡¬æˆªæ–­ï¼‰

**åŸç†**ï¼šæ’åºåç›´æ¥è¿‡æ»¤æ‰è´Ÿåˆ†itemã€‚

**å®ç°ä½ç½®**ï¼š`app/main.py Line 2217-2246`å

```python
# Line 2301åï¼ˆ_apply_rankingè°ƒç”¨åï¼‰
await _call_blocking(
    partial(_apply_ranking, scores, reasons, ...),
    ...
)

# æ–°å¢ï¼šç¡¬è¿‡æ»¤è´Ÿåˆ†
scores = {k: v for k, v in scores.items() if v >= 0}
if not scores:
    # å…¨éƒ¨è´Ÿåˆ†ï¼Œè§¦å‘fallback
    raise ValueError("All candidates have negative scores")
```

**ä¼˜ç‚¹**ï¼š
- ç®€å•ç›´æ¥
- ä¿è¯ç”¨æˆ·çœ‹ä¸åˆ°è´Ÿåˆ†

**ç¼ºç‚¹**ï¼š
- å¯èƒ½è¿‡æ»¤æ‰å¤ªå¤šitemï¼ˆ53%è´Ÿåˆ† â†’ åªå‰©47%ï¼‰
- æç«¯æƒ…å†µå…¨éƒ¨è´Ÿåˆ†ï¼Œæ— æ³•è¿”å›ç»“æœ

#### æ–¹æ¡ˆDï¼šè½¯æˆªæ–­ï¼ˆè´Ÿåˆ†è½¬æ­£ï¼‰

**åŸç†**ï¼šåœ¨rankerè¾“å‡ºæ—¶ï¼Œå°†è´Ÿåˆ†clipåˆ°0æˆ–åšoffsetã€‚

**å®ç°ä½ç½®**ï¼š`app/main.py Line 2236-2246`

```python
# Line 2236-2246: _apply_ranking_with_circuit_breaker
for dataset_id, prob in zip(features.index.astype(int), probabilities.values):
    if dataset_id not in scores:
        continue
    prob = float(prob)

    # æ–¹æ¡ˆD1: Clipè´Ÿåˆ†åˆ°0
    prob = max(0.0, prob)

    # æˆ– æ–¹æ¡ˆD2: å…¨å±€offsetï¼ˆå°†æœ€å°å€¼æå‡åˆ°0ï¼‰
    # prob = prob - global_min_prob  # global_min_prob = probabilities.min()

    if dataset_id in freshness_boost_lookup:
        freshness_boost = freshness_boost_lookup[dataset_id]
        scores[dataset_id] += prob * freshness_boost
    else:
        scores[dataset_id] += prob
```

**ä¼˜ç‚¹**ï¼š
- ä¿ç•™æ‰€æœ‰item
- åˆ†æ•°éè´Ÿï¼Œç”¨æˆ·å‹å¥½

**ç¼ºç‚¹**ï¼š
- æ”¹å˜äº†rankerçš„ç›¸å¯¹é¡ºåºï¼ˆclipä¼šä½¿æ‰€æœ‰è´Ÿåˆ†itemå˜æˆç›¸åŒåˆ†æ•°0ï¼‰
- éœ€è¦éªŒè¯å¯¹æ¨èè´¨é‡çš„å½±å“

#### æ–¹æ¡ˆEï¼šPopularå¬å›æ·»åŠ ç±»åˆ«è¿‡æ»¤

**åŸç†**ï¼šPopularå¬å›æ—¶åªä¿ç•™ä¸targetåŒç±»åˆ«çš„itemã€‚

**å®ç°ä½ç½®**ï¼š`app/main.py Line 1684-1697`

```python
# æ–°å¢ï¼šè·å–targetçš„ç±»åˆ«/æ ‡ç­¾
target_tags = dataset_tags.get(target_id, [])
target_category = _extract_primary_category(target_tags)  # éœ€è¦å®ç°

popular_scores = {}
for idx, item_id in enumerate(popular):
    if item_id == target_id or item_id in scores:
        continue

    # æ–°å¢ï¼šç±»åˆ«è¿‡æ»¤
    item_tags = dataset_tags.get(item_id, [])
    item_category = _extract_primary_category(item_tags)
    if target_category and item_category != target_category:
        continue  # ä¸åŒç±»åˆ«ï¼Œè·³è¿‡

    popular_scores[item_id] = 1.0 - (idx / max(len(popular), 1)) * 0.9
    if len(popular_scores) >= limit * 5:
        break
```

**ä¼˜ç‚¹**ï¼š
- æå‡Popularå¬å›è´¨é‡
- å‡å°‘ä¸ç›¸å…³itemè¢«rankeré‡åº¦æƒ©ç½š

**ç¼ºç‚¹**ï¼š
- éœ€è¦å®šä¹‰ç±»åˆ«ä½“ç³»ï¼ˆtagå¤ªç»†ç²’åº¦ï¼Œéœ€è¦å½’ç±»ï¼‰
- å¯èƒ½å¯¼è‡´Popularå¬å›æ•°é‡ä¸è¶³

#### æ–¹æ¡ˆFï¼šé™ä½Popularæƒé‡

**åŸç†**ï¼šå°†Popularæƒé‡ä»0.1é™åˆ°0.05ï¼Œå‡å°‘å…¶å½±å“ã€‚

**å®ç°ä½ç½®**ï¼š`app/main.py Line 183-188`

```python
DEFAULT_CHANNEL_WEIGHTS = {
    "behavior": 1.2,
    "content": 1.0,
    "vector": 0.8,
    "popular": 0.05,  # ä»0.1é™åˆ°0.05
}
```

**ä¼˜ç‚¹**ï¼š
- 1è¡Œä»£ç 
- ç«‹å³ç”Ÿæ•ˆ

**ç¼ºç‚¹**ï¼š
- æ²»æ ‡ä¸æ²»æœ¬ï¼ŒPopularå¬å›ä»ç„¶ä¸ç›¸å…³
- æƒé‡è¿‡ä½å¯èƒ½å¤±å»å¤šæ ·æ€§ä»·å€¼

### æ¨èå®æ–½è·¯å¾„

**P0ï¼ˆç«‹å³ä¿®å¤ï¼Œ1-2å°æ—¶ï¼‰**ï¼š
1. **ä¿®å¤MMRåˆ†æ•°å±•ç¤º**ï¼šé‡‡ç”¨æ–¹æ¡ˆAï¼ˆåºå·åˆ†æ•°ï¼‰ï¼Œ5è¡Œä»£ç 
2. **è¿‡æ»¤è´Ÿåˆ†**ï¼šé‡‡ç”¨æ–¹æ¡ˆDï¼ˆè½¯æˆªæ–­ï¼‰ï¼Œ10è¡Œä»£ç ï¼Œé…åˆæ–¹æ¡ˆCä½œä¸ºä¿åº•

**P1ï¼ˆçŸ­æœŸä¼˜åŒ–ï¼Œ1å¤©ï¼‰**ï¼š
3. **é™ä½Popularæƒé‡**ï¼šé‡‡ç”¨æ–¹æ¡ˆFï¼Œè§‚å¯Ÿè´Ÿåˆ†å æ¯”å˜åŒ–
4. **A/Bæµ‹è¯•**ï¼šå¯¹æ¯”è½¯æˆªæ–­vsç¡¬æˆªæ–­çš„CTRå½±å“

**P2ï¼ˆé•¿æœŸä¼˜åŒ–ï¼Œ1å‘¨ï¼‰**ï¼š
5. **Popularå¬å›ä¼˜åŒ–**ï¼šé‡‡ç”¨æ–¹æ¡ˆEï¼ˆç±»åˆ«è¿‡æ»¤ï¼‰ï¼Œéœ€è¦è®¾è®¡ç±»åˆ«æ˜ å°„
6. **Rankeræ¨¡å‹ä¼˜åŒ–**ï¼šé‡æ–°è®­ç»ƒæ—¶è°ƒæ•´ç‰¹å¾/æ ·æœ¬ï¼Œå‡å°‘è´Ÿåˆ†è¾“å‡º

### ä¾èµ–æ–‡ä»¶æ¸…å•

**éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶**ï¼š
- `/home/ubuntu/recommend/app/main.py`
  - `_build_response_items()` (Line 1246-1320)
  - `_apply_ranking_with_circuit_breaker()` (Line 2217-2251)
  - `_combine_scores_with_weights()` (Line 1684-1697ï¼Œå¯é€‰Popularè¿‡æ»¤)
  - `DEFAULT_CHANNEL_WEIGHTS` (Line 183-188ï¼Œå¯é€‰é™æƒ)

**éœ€è¦è¯»å–çš„é…ç½®**ï¼š
- `/home/ubuntu/recommend/models/top_items.json` - Popularæ¦œå•
- `/home/ubuntu/recommend/models/rank_model.pkl` - LightGBM rankeræ¨¡å‹

**ä¸éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶**ï¼ˆç†è§£å³å¯ï¼‰ï¼š
- `/home/ubuntu/recommend/pipeline/train_models.py` - æ¨¡å‹è®­ç»ƒé€»è¾‘
- æ•°æ®æ–‡ä»¶ï¼š`data/processed/*.parquet`

### æµ‹è¯•éªŒè¯æ–¹æ³•

**æœ¬åœ°æµ‹è¯•**ï¼š

```bash
# 1. å¯åŠ¨æœåŠ¡
docker-compose up -d app

# 2. æµ‹è¯•æ¡ˆä¾‹ï¼ˆå¤ç°è´Ÿåˆ†é—®é¢˜ï¼‰
curl "http://localhost:8000/recommend/detail/13003?user_id=1997&limit=30"

# 3. éªŒè¯ç‚¹
# - æ‰€æœ‰itemçš„scoreä¸¥æ ¼é™åº
# - è´Ÿåˆ†itemå æ¯”<10%ï¼ˆæˆ–0ï¼‰
# - reasonå­—æ®µåˆç†
# - å“åº”æ—¶é—´<500ms

# 4. å¯¹æ¯”ä¿®å¤å‰åçš„JSONè¾“å‡º
diff before.json after.json
```

**ç”Ÿäº§éªŒè¯**ï¼š

```python
# åœ¨æ—¥å¿—ä¸­ç»Ÿè®¡è´Ÿåˆ†å æ¯”
import json

total_items = 0
negative_items = 0

for line in open("exposure.log"):
    event = json.loads(line)
    for item in event.get("items", []):
        total_items += 1
        if item["score"] < 0:
            negative_items += 1

print(f"è´Ÿåˆ†å æ¯”: {negative_items / total_items * 100:.1f}%")
```

### æ€§èƒ½å½±å“è¯„ä¼°

**æ–¹æ¡ˆAï¼ˆåºå·åˆ†æ•°ï¼‰**ï¼š
- æ—¶é—´å¤æ‚åº¦ï¼šO(n)ï¼Œnæ˜¯limit
- å†…å­˜ï¼šæ— é¢å¤–å¼€é”€
- å»¶è¿Ÿå½±å“ï¼š<0.1ms

**æ–¹æ¡ˆDï¼ˆè½¯æˆªæ–­ï¼‰**ï¼š
- æ—¶é—´å¤æ‚åº¦ï¼šO(n)
- å†…å­˜ï¼šæ— é¢å¤–å¼€é”€
- å»¶è¿Ÿå½±å“ï¼š<0.1ms

**æ–¹æ¡ˆEï¼ˆPopularç±»åˆ«è¿‡æ»¤ï¼‰**ï¼š
- æ—¶é—´å¤æ‚åº¦ï¼šO(m)ï¼Œmæ˜¯popularåˆ—è¡¨é•¿åº¦ï¼ˆ50ï¼‰
- å†…å­˜ï¼šéœ€è¦åŠ è½½dataset_tagsï¼ˆå·²åœ¨å†…å­˜ä¸­ï¼‰
- å»¶è¿Ÿå½±å“ï¼š<1ms

**æ€»ä½“è¯„ä¼°**ï¼šæ‰€æœ‰æ–¹æ¡ˆæ€§èƒ½å½±å“å¯å¿½ç•¥ï¼Œä¸ä¼šå¯¼è‡´P99å»¶è¿Ÿé€€åŒ–ã€‚

---

## Work Log

### 2025-12-27 - Task Complete

#### é—®é¢˜å‘ç°ä¸è¯Šæ–­
- **ç”Ÿäº§é—®é¢˜åˆ†æ**ï¼šæ¨èç»“æœ53%ä¸ºè´Ÿåˆ†ï¼ˆ16/30ï¼‰ï¼ŒscoreèŒƒå›´ä»-2.89åˆ°2.057
- **æ ¹æœ¬åŸå› **ï¼šLightGBM rankerè¾“å‡ºæœªå½’ä¸€åŒ–åˆ†æ•°(-âˆ,+âˆ)ï¼ŒPopularå¬å›ç¼ºä¹è´¨é‡è¿‡æ»¤
- **ç”¨æˆ·å½±å“**ï¼šè´Ÿåˆ†æš—ç¤ºè´¨é‡å·®ï¼Œä½†ä»ç„¶å±•ç¤ºï¼Œå¯¼è‡´ç”¨æˆ·ä¿¡ä»»åº¦ä¸‹é™

#### ä»£ç å®ç°ï¼ˆapp/main.pyï¼‰

**1. è´Ÿåˆ†ç¡¬æˆªæ–­æœºåˆ¶ (Line 2336-2361)**
- å®æ–½ç¡¬æˆªæ–­è¿‡æ»¤æ‰€æœ‰score<0çš„item
- æ·»åŠ fallbackç­–ç•¥ï¼šå…¨éƒ¨è´Ÿåˆ†æ—¶ä¿ç•™top 50%ï¼ˆè‡³å°‘5ä¸ªï¼‰
- è®°å½•è¯¦ç»†æ—¥å¿—ï¼šè´Ÿåˆ†æ¯”ä¾‹ã€è¿‡æ»¤æ•°é‡

**2. Popularå¬å›è´¨é‡ä¼˜åŒ– (Line 1688-1750)**
- **æ–°å¢è´¨é‡è¿‡æ»¤è§„åˆ™**ï¼š
  - ä½ä»·ä¸”æ— äººæ°”ï¼šprice < 1.90 AND interaction < 66
  - é•¿æœŸä¸æ´»è·ƒä¸”äº¤äº’å°‘ï¼šdays_inactive > 180 AND interaction < 30
- **æ€§èƒ½ä¼˜åŒ–**ï¼šæ‰¹é‡é¢„æŸ¥è¯¢ä»£æ›¿å¾ªç¯æŸ¥è¯¢ï¼ˆé¿å…DataFrame fragmentationï¼‰
- **å¼‚å¸¸å¤„ç†**ï¼šKeyError/ValueError/TypeErrorå®‰å…¨æ•è·
- **ç›‘æ§æ—¥å¿—**ï¼šè®°å½•è¿‡æ»¤æ•°é‡å’Œä¿ç•™æ¯”ä¾‹

**3. Tagå¬å›bugä¿®å¤ (Line 1506-1507)**
- ä¿®å¤æ ‡ç­¾å¤§å°å†™ä¸ç»Ÿä¸€å¯¼è‡´overlapè®¡ç®—é”™è¯¯
- ç»Ÿä¸€ä½¿ç”¨lowercaseå¤„ç†targetå’Œcandidate tags

#### ä»£ç å®¡æŸ¥ä¿®å¤

**Critical Issues (3ä¸ªå…¨éƒ¨ä¿®å¤)**
1. âœ… Tag overlapè®¡ç®— - æ ‡ç­¾å°å†™åŒ–ç»Ÿä¸€
2. âœ… Popular Seriesè®¿é—® - ä½¿ç”¨try-except + ç±»å‹è½¬æ¢
3. âœ… è´Ÿåˆ†fallbackç­–ç•¥ - å…¨éƒ¨è´Ÿåˆ†æ—¶ä¿ç•™top 50%

**Warnings (2/4ä¿®å¤)**
1. âœ… Popularè¿‡æ»¤é€»è¾‘æ”¹è¿› - ANDç»„åˆæ¡ä»¶é¿å…è¯¯æ€
2. âœ… Popularæ‰¹é‡æŸ¥è¯¢ä¼˜åŒ– - å‡å°‘DataFrameè®¿é—®æ¬¡æ•°
3. â­ï¸ ç¼“å­˜æ—¶é—´æ¡¶ - æ¶æ„çº§åˆ«ä¿®æ”¹ï¼Œä¸åœ¨æœ¬ä»»åŠ¡èŒƒå›´

#### æŠ€æœ¯å†³ç­–

**ä¸ºä½•é€‰æ‹©ç¡¬æˆªæ–­è€Œéè½¯æˆªæ–­**ï¼š
- è½¯æˆªæ–­ï¼ˆclipè´Ÿåˆ†åˆ°0ï¼‰ä¼šä½¿æ‰€æœ‰è´Ÿåˆ†itemåˆ†æ•°ç›¸åŒï¼Œå¤±å»æ’åºä¿¡æ¯
- ç¡¬æˆªæ–­ç›´æ¥ç§»é™¤ï¼Œä¿æŒå‰©ä½™itemçš„ç›¸å¯¹é¡ºåº
- Fallbackç­–ç•¥ä¿è¯æç«¯æƒ…å†µä¸‹ä»æœ‰æ¨èè¿”å›

**Popularè¿‡æ»¤æ ‡å‡†**ï¼š
- ä»ORé€»è¾‘ï¼ˆprice<1.9 OR interaction<66 OR inactive>180ï¼‰æ”¹ä¸ºANDé€»è¾‘
- é¿å…è¯¯æ€ï¼šé«˜ä»·ä½†æ–°å“ï¼ˆinteractionä½ï¼‰ã€é•¿æœŸä¸æ´»è·ƒä½†é«˜è´¨é‡item
- æ›´ç²¾å‡†å®šä½ä½è´¨é‡ç»„åˆä¿¡å·

#### æ–‡ä»¶ä¿®æ”¹æ¸…å•
- `/home/ubuntu/recommend/app/main.py` - 3ä¸ªä½ç½®ä¿®æ”¹ï¼Œå…±çº¦80è¡Œä»£ç å˜æ›´

#### æµ‹è¯•éªŒè¯
- â³ æœ¬åœ°æµ‹è¯•ï¼šè·³è¿‡ï¼ˆæœ¬åœ°æ•°æ®ä¸ç”Ÿäº§ä¸ä¸€è‡´ï¼‰
- â³ ç”Ÿäº§éªŒè¯ï¼šå¾…éƒ¨ç½²åè§‚å¯Ÿè´Ÿåˆ†å æ¯”ã€Popularè¿‡æ»¤ç‡ã€CTRå½±å“

#### Next Steps
1. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
2. ç›‘æ§æŒ‡æ ‡ï¼š
   - è´Ÿåˆ†itemè¿‡æ»¤æ•°é‡/æ¯”ä¾‹
   - Popularå¬å›è¿‡æ»¤ç‡
   - fallbackè§¦å‘é¢‘ç‡
   - CTR/ç”¨æˆ·æ»¡æ„åº¦å˜åŒ–
3. æ ¹æ®ç›‘æ§ç»“æœè°ƒæ•´è¿‡æ»¤é˜ˆå€¼
4. è€ƒè™‘ç¼“å­˜æ—¶é—´æ¡¶ä¼˜åŒ–ï¼ˆç‹¬ç«‹ä»»åŠ¡ï¼‰
